{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3 - Emotion Tweet Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YmummvAm3ZOf"
   },
   "source": [
    "### Grup 5 - AI 2\n",
    "\n",
    "Anggota Kelompok: \n",
    "* Diah Ayu Setyaningsih\n",
    "* I Nyoman Warsana\n",
    "* Iman Santoso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lwIeFG9F88Me"
   },
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TdsiOLHE3LbB"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "colab_type": "code",
    "id": "zz4cl2EW4D7x",
    "outputId": "bd9ac838-bde3-4d2e-db02-a6394d3e2511"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>love</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pessimism</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-En-21441</td>\n",
       "      <td>“Worry is a down payment on a problem you may ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-En-31535</td>\n",
       "      <td>Whatever you decide to do make sure it makes y...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-En-21068</td>\n",
       "      <td>@Max_Kellerman  it also helps that the majorit...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-En-31436</td>\n",
       "      <td>Accept the challenges so that you can literall...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-En-22195</td>\n",
       "      <td>My roommate: it's okay that we can't spell bec...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID                                              Tweet  anger  \\\n",
       "0  2017-En-21441  “Worry is a down payment on a problem you may ...      0   \n",
       "1  2017-En-31535  Whatever you decide to do make sure it makes y...      0   \n",
       "2  2017-En-21068  @Max_Kellerman  it also helps that the majorit...      1   \n",
       "3  2017-En-31436  Accept the challenges so that you can literall...      0   \n",
       "4  2017-En-22195  My roommate: it's okay that we can't spell bec...      1   \n",
       "\n",
       "   anticipation  disgust  fear  joy  love  optimism  pessimism  sadness  \\\n",
       "0             1        0     0    0     0         1          0        0   \n",
       "1             0        0     0    1     1         1          0        0   \n",
       "2             0        1     0    1     0         1          0        0   \n",
       "3             0        0     0    1     0         1          0        0   \n",
       "4             0        1     0    0     0         0          0        0   \n",
       "\n",
       "   surprise  trust  \n",
       "0         0      1  \n",
       "1         0      0  \n",
       "2         0      0  \n",
       "3         0      0  \n",
       "4         0      0  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.read_csv('2018-E-c-En-train.txt', sep='\\t')\n",
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "kCuXnPpVjT7E",
    "outputId": "cf0fc040-b857-4fb6-9c24-5dfe72c842d7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ASUS\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "tokenizer = WordPunctTokenizer()\n",
    "mention_pattern = r'@[\\w]+'\n",
    "http_pattern = r'(http|https)?://[^ ]+'\n",
    "www_pattern = r'www.[^ ]+'\n",
    "pattern = r'|'.join((mention_pattern, http_pattern))\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# sub tweet_cleaner\n",
    "def tweet_cleaner(tweet):\n",
    "  soup = BeautifulSoup(tweet, 'lxml')\n",
    "  text = soup.get_text()\n",
    "  sub = re.sub(pattern, '', text)\n",
    "  try:\n",
    "    clean_text = sub.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
    "  except:\n",
    "    clean_text = sub\n",
    "  letter_text = re.sub('[^\\w]', ' ', clean_text)\n",
    "  letter_text = re.sub(www_pattern, '', letter_text)\n",
    "  letter_lc = letter_text.lower()\n",
    "  word_list = tokenizer.tokenize(letter_lc)\n",
    "  clean_word_list = word_list[:]\n",
    "  for word in clean_word_list:\n",
    "    if word in stop_words:\n",
    "      clean_word_list.remove(word)\n",
    "  word = (\" \".join(clean_word_list)).strip()\n",
    "  return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "cdIF2qV_iLip",
    "outputId": "f0768816-c036-4bcf-f2b9-a88cda56a8fe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>love</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pessimism</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-En-21441</td>\n",
       "      <td>worry a payment a problem may never joyce meye...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-En-31535</td>\n",
       "      <td>whatever decide do make sure makes happy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-En-21068</td>\n",
       "      <td>also helps the majority nfl coaching inept of ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-En-31436</td>\n",
       "      <td>accept challenges that can literally even feel...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-En-22195</td>\n",
       "      <td>roommate s okay we t spell we autocorrect terr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID                                              Tweet  anger  \\\n",
       "0  2017-En-21441  worry a payment a problem may never joyce meye...      0   \n",
       "1  2017-En-31535           whatever decide do make sure makes happy      0   \n",
       "2  2017-En-21068  also helps the majority nfl coaching inept of ...      1   \n",
       "3  2017-En-31436  accept challenges that can literally even feel...      0   \n",
       "4  2017-En-22195  roommate s okay we t spell we autocorrect terr...      1   \n",
       "\n",
       "   anticipation  disgust  fear  joy  love  optimism  pessimism  sadness  \\\n",
       "0             1        0     0    0     0         1          0        0   \n",
       "1             0        0     0    1     1         1          0        0   \n",
       "2             0        1     0    1     0         1          0        0   \n",
       "3             0        0     0    1     0         1          0        0   \n",
       "4             0        1     0    0     0         0          0        0   \n",
       "\n",
       "   surprise  trust  \n",
       "0         0      1  \n",
       "1         0      0  \n",
       "2         0      0  \n",
       "3         0      0  \n",
       "4         0      0  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaning train tweet\n",
    "clean_tweet_train = []\n",
    "clean_train_df = data_train[:]\n",
    "for i in range(len(data_train.index)):\n",
    "  clean_tweet_train.append(tweet_cleaner(data_train['Tweet'][i]))\n",
    "clean_train_df['Tweet'] = clean_tweet_train\n",
    "clean_train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wj-UE4dACCT5"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9ahVWtzns470"
   },
   "outputs": [],
   "source": [
    "tweet = clean_train_df['Tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HIbBJlMVDJNp"
   },
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "messages_bow = count_vect.fit_transform(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v5dwJUW_DYj4"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mS0Ds-S7DcXk"
   },
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "messages_tfidf = tfidf_transformer.fit_transform(messages_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "ctNVcDssEXae",
    "outputId": "664599bd-5221-435b-a3bb-e8ad1febccc1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>love</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pessimism</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   anger  anticipation  disgust  fear  joy  love  optimism  pessimism  \\\n",
       "0      0             1        0     0    0     0         1          0   \n",
       "1      0             0        0     0    1     1         1          0   \n",
       "2      1             0        1     0    1     0         1          0   \n",
       "3      0             0        0     0    1     0         1          0   \n",
       "4      1             0        1     0    0     0         0          0   \n",
       "\n",
       "   sadness  surprise  trust  \n",
       "0        0         0      1  \n",
       "1        0         0      0  \n",
       "2        0         0      0  \n",
       "3        0         0      0  \n",
       "4        0         0      0  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = clean_train_df.columns\n",
    "x = messages_tfidf\n",
    "y = clean_train_df[col[2:]]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1YhJ5VvlET3W"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Etth5Z-FPbE"
   },
   "outputs": [],
   "source": [
    "text_train, text_test, output_train, output_test = train_test_split(x, y, \n",
    "                                                                    train_size=0.75, \n",
    "                                                                    test_size=0.25, \n",
    "                                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D9i43wepDqkw"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5zcaEmJFGLwK"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Bn4jDt-OF6pm",
    "outputId": "c9930896-d474-4efd-93a6-62d3cee585b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model anger:  MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model anger:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "Best Model anger:  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "Best Model anticipation:  MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model disgust:  MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model disgust:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "Best Model fear:  MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model fear:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "Best Model fear:  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "Best Model fear:  DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "Best Model joy:  MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model joy:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "Best Model love:  MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model love:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "Best Model optimism:  MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model optimism:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "Best Model pessimism:  MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model pessimism:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "Best Model sadness:  MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model sadness:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "Best Model sadness:  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "Best Model surprise:  MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model surprise:  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "Best Model trust:  MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "C:\\Users\\ASUS\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "clf = [MultinomialNB(), SVC(), LogisticRegression(), RandomForestClassifier(), DecisionTreeClassifier()]\n",
    "df_accuracy = {}\n",
    "best_clf = {}\n",
    "for i in col[2:]:\n",
    "  best_accuracy = 0\n",
    "  df_accuracy[i] = []\n",
    "  for classifier in clf:\n",
    "    model = classifier\n",
    "    model.fit(text_train, output_train[i])\n",
    "    hasil = model.predict(text_test)\n",
    "    score = accuracy_score(output_test[i],hasil)\n",
    "    df_accuracy[i].append(score)\n",
    "    joblib_file = i + \"_model.pkl\"\n",
    "    if best_accuracy < score:\n",
    "      best_accuracy = score\n",
    "      best_clf.update({i:classifier})\n",
    "      print('Best Model {}: '.format(i), model)\n",
    "      joblib.dump(model, joblib_file)\n",
    "    else:\n",
    "      best_clf[i] = classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "7S-mAACXGWF4",
    "outputId": "79c5c4de-d3e9-4183-f7f6-49e6736880f8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>love</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pessimism</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.735673</td>\n",
       "      <td>0.852047</td>\n",
       "      <td>0.715205</td>\n",
       "      <td>0.819298</td>\n",
       "      <td>0.760819</td>\n",
       "      <td>0.893567</td>\n",
       "      <td>0.739181</td>\n",
       "      <td>0.880117</td>\n",
       "      <td>0.735088</td>\n",
       "      <td>0.945029</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.628070</td>\n",
       "      <td>0.852047</td>\n",
       "      <td>0.623977</td>\n",
       "      <td>0.810526</td>\n",
       "      <td>0.646784</td>\n",
       "      <td>0.892982</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.880117</td>\n",
       "      <td>0.705848</td>\n",
       "      <td>0.945029</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.774854</td>\n",
       "      <td>0.852047</td>\n",
       "      <td>0.740936</td>\n",
       "      <td>0.845614</td>\n",
       "      <td>0.799415</td>\n",
       "      <td>0.898246</td>\n",
       "      <td>0.762573</td>\n",
       "      <td>0.881287</td>\n",
       "      <td>0.762573</td>\n",
       "      <td>0.946199</td>\n",
       "      <td>0.947368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.776608</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.718129</td>\n",
       "      <td>0.884795</td>\n",
       "      <td>0.786550</td>\n",
       "      <td>0.897661</td>\n",
       "      <td>0.756725</td>\n",
       "      <td>0.877193</td>\n",
       "      <td>0.781287</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.942105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.745029</td>\n",
       "      <td>0.798246</td>\n",
       "      <td>0.678947</td>\n",
       "      <td>0.886550</td>\n",
       "      <td>0.758480</td>\n",
       "      <td>0.875439</td>\n",
       "      <td>0.729825</td>\n",
       "      <td>0.849708</td>\n",
       "      <td>0.735673</td>\n",
       "      <td>0.929240</td>\n",
       "      <td>0.911696</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           anger  anticipation   disgust      fear       joy  \\\n",
       "MultinomialNB           0.735673      0.852047  0.715205  0.819298  0.760819   \n",
       "SVC                     0.628070      0.852047  0.623977  0.810526  0.646784   \n",
       "LogisticRegression      0.774854      0.852047  0.740936  0.845614  0.799415   \n",
       "RandomForestClassifier  0.776608      0.842105  0.718129  0.884795  0.786550   \n",
       "DecisionTreeClassifier  0.745029      0.798246  0.678947  0.886550  0.758480   \n",
       "\n",
       "                            love  optimism  pessimism   sadness  surprise  \\\n",
       "MultinomialNB           0.893567  0.739181   0.880117  0.735088  0.945029   \n",
       "SVC                     0.892982  0.710526   0.880117  0.705848  0.945029   \n",
       "LogisticRegression      0.898246  0.762573   0.881287  0.762573  0.946199   \n",
       "RandomForestClassifier  0.897661  0.756725   0.877193  0.781287  0.944444   \n",
       "DecisionTreeClassifier  0.875439  0.729825   0.849708  0.735673  0.929240   \n",
       "\n",
       "                           trust  \n",
       "MultinomialNB           0.947368  \n",
       "SVC                     0.947368  \n",
       "LogisticRegression      0.947368  \n",
       "RandomForestClassifier  0.942105  \n",
       "DecisionTreeClassifier  0.911696  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_accuracy = pd.DataFrame(df_accuracy)\n",
    "method = [str(classifier).split(\"(\")[0] for classifier in clf]\n",
    "df_accuracy.rename(index={i:method[i] for i in range(len(clf))}, inplace=True)\n",
    "df_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U3y9PULw8gXl"
   },
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T-or5ruld3Gv"
   },
   "outputs": [],
   "source": [
    "data_test = pd.read_csv('2018-E-c-En-test.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "YcUPeSWer7UF",
    "outputId": "7c0d1104-15f5-4a00-f58b-612c23fdce4e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3259, 13)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleaning test tweet\n",
    "clean_tweet_test = []\n",
    "clean_test_df = data_test[:]\n",
    "for i in range(len(data_test.index)):\n",
    "  clean_tweet_test.append(tweet_cleaner(data_test['Tweet'][i]))\n",
    "clean_test_df['Tweet'] = clean_tweet_test\n",
    "clean_test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "X-PrsXw7XF9l",
    "outputId": "3b5d745b-974d-4f8a-dcde-257f5e4e683e"
   },
   "outputs": [],
   "source": [
    "tweet_test = clean_test_df['Tweet']\n",
    "X_test_count = count_vect.transform(tweet_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "FdCyUT_bBzI6",
    "outputId": "c0103bbc-e8ce-4329-b9b4-277c01668839"
   },
   "outputs": [],
   "source": [
    "X_test_tfidf = tfidf_transformer.transform(X_test_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "oz6Pwod3Y3Db",
    "outputId": "ba937f1d-a526-4a6d-8008-97bdbc867ab4"
   },
   "outputs": [],
   "source": [
    "col_test = clean_test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q1YaHVgeepmv"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>love</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pessimism</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-En-01559</td>\n",
       "      <td>dont worry indian army on ways dispatch terror...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-En-03739</td>\n",
       "      <td>academy sciences eschews normally sober tone s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-En-00385</td>\n",
       "      <td>blew opportunity __ mad</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-En-03001</td>\n",
       "      <td>time 2 weeks will 30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-En-01988</td>\n",
       "      <td>deppression real partners w depressed people t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-En-03463</td>\n",
       "      <td>interesting choice words you confirming govern...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-En-04315</td>\n",
       "      <td>cnn for sure</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-En-01426</td>\n",
       "      <td>distance once stretched your friends impose se...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-En-03332</td>\n",
       "      <td>happy confident kind n n kissableslovesmshopma...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-En-01938</td>\n",
       "      <td>visit hospital care triggered trauma accident ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018-En-00264</td>\n",
       "      <td>thanks dollis hill relentless tenacious pc lea...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018-En-00840</td>\n",
       "      <td>ve retweeted followed good luck</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2018-En-01343</td>\n",
       "      <td>welcome mpsvt are delighted have grateful mpsv...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2018-En-03467</td>\n",
       "      <td>makes feel joyful</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2018-En-01203</td>\n",
       "      <td>bitter afternoon sweetness all lenovo</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2018-En-02225</td>\n",
       "      <td>people need learn to smile laugh live life</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2018-En-00375</td>\n",
       "      <td>are in together we sink together we swim together</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2018-En-03838</td>\n",
       "      <td>life be beautiful you start seeing things diff...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2018-En-01077</td>\n",
       "      <td>am revolting</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2018-En-01569</td>\n",
       "      <td>rin might ever appeared gloomy to a melodramat...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2018-En-02679</td>\n",
       "      <td>wow really t believe four years already went f...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2018-En-01476</td>\n",
       "      <td>middle class may sink without struggles the wo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2018-En-03943</td>\n",
       "      <td>remember watching talk show class 1 day the ch...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2018-En-04100</td>\n",
       "      <td>i hear room my house my brothers seriously dis...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2018-En-01586</td>\n",
       "      <td>happy birthday beautiful pussy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2018-En-02990</td>\n",
       "      <td>need a change restless</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2018-En-00590</td>\n",
       "      <td>m glad despite weeks being mia can still talk ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2018-En-01227</td>\n",
       "      <td>cmbyn screen august 4 6 miff</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2018-En-03682</td>\n",
       "      <td>get donovan of soccer booth s awful s bitter m...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2018-En-03354</td>\n",
       "      <td>can u sold many copies ur game so many fucking...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3229</th>\n",
       "      <td>2018-En-03537</td>\n",
       "      <td>are successful moment start toward laudable go...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3230</th>\n",
       "      <td>2018-En-01933</td>\n",
       "      <td>welcome new followers will mostly talking happ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3231</th>\n",
       "      <td>2018-En-02436</td>\n",
       "      <td>ah see clever n ruby nodded head putting hands...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3232</th>\n",
       "      <td>2018-En-04099</td>\n",
       "      <td>happy birthday baby wish happiness liiiiife</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3233</th>\n",
       "      <td>2018-En-01145</td>\n",
       "      <td>everyday s something new</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3234</th>\n",
       "      <td>2018-En-03841</td>\n",
       "      <td>well s funny cause all know is serious russian...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3235</th>\n",
       "      <td>2018-En-03395</td>\n",
       "      <td>delusional disgraceful democrat enough said</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3236</th>\n",
       "      <td>2018-En-03995</td>\n",
       "      <td>subscribe my youtube comedy page greg offutt d...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3237</th>\n",
       "      <td>2018-En-04167</td>\n",
       "      <td>definitely crying the worst nightmare ve in aw...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3238</th>\n",
       "      <td>2018-En-04211</td>\n",
       "      <td>every president said can really govern foe 18 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3239</th>\n",
       "      <td>2018-En-00671</td>\n",
       "      <td>best customer are pleased inform that order be...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3240</th>\n",
       "      <td>2018-En-00287</td>\n",
       "      <td>glee my childhood</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3241</th>\n",
       "      <td>2018-En-04275</td>\n",
       "      <td>t blow top spicy foods boost production feel g...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3242</th>\n",
       "      <td>2018-En-02838</td>\n",
       "      <td>blowing</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3243</th>\n",
       "      <td>2018-En-00707</td>\n",
       "      <td>much niggas knew my mum lived we moved out def...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3244</th>\n",
       "      <td>2018-En-02340</td>\n",
       "      <td>immature trumpy sad one guys this represent in...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3245</th>\n",
       "      <td>2018-En-00205</td>\n",
       "      <td>don know like but whenever i see i smile feel ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>2018-En-02053</td>\n",
       "      <td>thank very much keep gettin excited kid ur bda...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>2018-En-04237</td>\n",
       "      <td>first was steaming pussy garlic this ao give</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3248</th>\n",
       "      <td>2018-En-02247</td>\n",
       "      <td>rofl</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3249</th>\n",
       "      <td>2018-En-02676</td>\n",
       "      <td>fast furious marathon soon</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3250</th>\n",
       "      <td>2018-En-04010</td>\n",
       "      <td>let ask a question n ndid really let worry you...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3251</th>\n",
       "      <td>2018-En-01949</td>\n",
       "      <td>heartbreaking moment realise has stopped follo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3252</th>\n",
       "      <td>2018-En-02405</td>\n",
       "      <td>need sparkling bodysuit occasion in case s eme...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3253</th>\n",
       "      <td>2018-En-01862</td>\n",
       "      <td>ve finished reading simply mind blogging write...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3254</th>\n",
       "      <td>2018-En-03848</td>\n",
       "      <td>shaft abrasions panties merely shifted the sid...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3255</th>\n",
       "      <td>2018-En-00416</td>\n",
       "      <td>heard remothered indie horror game writing va ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3256</th>\n",
       "      <td>2018-En-03717</td>\n",
       "      <td>this fake outrage all need stop</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3257</th>\n",
       "      <td>2018-En-03504</td>\n",
       "      <td>would ever grateful you could record garden fo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3258</th>\n",
       "      <td>2018-En-00115</td>\n",
       "      <td>m wholesome drunk sends people memes complimen...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3259 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID                                              Tweet  anger  \\\n",
       "0     2018-En-01559  dont worry indian army on ways dispatch terror...      0   \n",
       "1     2018-En-03739  academy sciences eschews normally sober tone s...      0   \n",
       "2     2018-En-00385                            blew opportunity __ mad      1   \n",
       "3     2018-En-03001                               time 2 weeks will 30      0   \n",
       "4     2018-En-01988  deppression real partners w depressed people t...      1   \n",
       "5     2018-En-03463  interesting choice words you confirming govern...      1   \n",
       "6     2018-En-04315                                       cnn for sure      0   \n",
       "7     2018-En-01426  distance once stretched your friends impose se...      0   \n",
       "8     2018-En-03332  happy confident kind n n kissableslovesmshopma...      0   \n",
       "9     2018-En-01938  visit hospital care triggered trauma accident ...      0   \n",
       "10    2018-En-00264  thanks dollis hill relentless tenacious pc lea...      0   \n",
       "11    2018-En-00840                    ve retweeted followed good luck      0   \n",
       "12    2018-En-01343  welcome mpsvt are delighted have grateful mpsv...      0   \n",
       "13    2018-En-03467                                  makes feel joyful      0   \n",
       "14    2018-En-01203              bitter afternoon sweetness all lenovo      1   \n",
       "15    2018-En-02225         people need learn to smile laugh live life      0   \n",
       "16    2018-En-00375  are in together we sink together we swim together      0   \n",
       "17    2018-En-03838  life be beautiful you start seeing things diff...      0   \n",
       "18    2018-En-01077                                       am revolting      0   \n",
       "19    2018-En-01569  rin might ever appeared gloomy to a melodramat...      0   \n",
       "20    2018-En-02679  wow really t believe four years already went f...      0   \n",
       "21    2018-En-01476  middle class may sink without struggles the wo...      0   \n",
       "22    2018-En-03943  remember watching talk show class 1 day the ch...      0   \n",
       "23    2018-En-04100  i hear room my house my brothers seriously dis...      0   \n",
       "24    2018-En-01586                     happy birthday beautiful pussy      0   \n",
       "25    2018-En-02990                             need a change restless      0   \n",
       "26    2018-En-00590  m glad despite weeks being mia can still talk ...      1   \n",
       "27    2018-En-01227                       cmbyn screen august 4 6 miff      0   \n",
       "28    2018-En-03682  get donovan of soccer booth s awful s bitter m...      1   \n",
       "29    2018-En-03354  can u sold many copies ur game so many fucking...      1   \n",
       "...             ...                                                ...    ...   \n",
       "3229  2018-En-03537  are successful moment start toward laudable go...      0   \n",
       "3230  2018-En-01933  welcome new followers will mostly talking happ...      0   \n",
       "3231  2018-En-02436  ah see clever n ruby nodded head putting hands...      0   \n",
       "3232  2018-En-04099        happy birthday baby wish happiness liiiiife      0   \n",
       "3233  2018-En-01145                           everyday s something new      0   \n",
       "3234  2018-En-03841  well s funny cause all know is serious russian...      0   \n",
       "3235  2018-En-03395        delusional disgraceful democrat enough said      0   \n",
       "3236  2018-En-03995  subscribe my youtube comedy page greg offutt d...      0   \n",
       "3237  2018-En-04167  definitely crying the worst nightmare ve in aw...      0   \n",
       "3238  2018-En-04211  every president said can really govern foe 18 ...      0   \n",
       "3239  2018-En-00671  best customer are pleased inform that order be...      1   \n",
       "3240  2018-En-00287                                  glee my childhood      0   \n",
       "3241  2018-En-04275  t blow top spicy foods boost production feel g...      0   \n",
       "3242  2018-En-02838                                            blowing      0   \n",
       "3243  2018-En-00707  much niggas knew my mum lived we moved out def...      0   \n",
       "3244  2018-En-02340  immature trumpy sad one guys this represent in...      1   \n",
       "3245  2018-En-00205  don know like but whenever i see i smile feel ...      0   \n",
       "3246  2018-En-02053  thank very much keep gettin excited kid ur bda...      0   \n",
       "3247  2018-En-04237       first was steaming pussy garlic this ao give      0   \n",
       "3248  2018-En-02247                                               rofl      0   \n",
       "3249  2018-En-02676                         fast furious marathon soon      1   \n",
       "3250  2018-En-04010  let ask a question n ndid really let worry you...      0   \n",
       "3251  2018-En-01949  heartbreaking moment realise has stopped follo...      0   \n",
       "3252  2018-En-02405  need sparkling bodysuit occasion in case s eme...      0   \n",
       "3253  2018-En-01862  ve finished reading simply mind blogging write...      0   \n",
       "3254  2018-En-03848  shaft abrasions panties merely shifted the sid...      0   \n",
       "3255  2018-En-00416  heard remothered indie horror game writing va ...      0   \n",
       "3256  2018-En-03717                    this fake outrage all need stop      1   \n",
       "3257  2018-En-03504  would ever grateful you could record garden fo...      0   \n",
       "3258  2018-En-00115  m wholesome drunk sends people memes complimen...      0   \n",
       "\n",
       "      anticipation  disgust  fear  joy  love  optimism  pessimism  sadness  \\\n",
       "0                0        0     1    0     0         0          0        0   \n",
       "1                0        0     0    0     0         0          0        0   \n",
       "2                0        0     0    0     0         0          0        0   \n",
       "3                0        0     0    0     0         0          0        0   \n",
       "4                0        0     1    0     0         0          0        0   \n",
       "5                0        0     1    0     0         0          0        0   \n",
       "6                0        0     0    0     0         0          0        0   \n",
       "7                0        0     0    0     0         0          0        0   \n",
       "8                0        0     0    1     0         1          0        0   \n",
       "9                0        0     0    0     0         0          0        1   \n",
       "10               0        0     0    1     0         0          0        0   \n",
       "11               0        0     0    1     0         0          0        0   \n",
       "12               0        0     0    1     0         0          0        0   \n",
       "13               0        0     0    1     0         0          0        0   \n",
       "14               0        1     0    0     0         0          0        0   \n",
       "15               0        0     0    1     0         1          0        0   \n",
       "16               0        0     0    0     0         0          0        0   \n",
       "17               0        0     0    1     0         1          0        0   \n",
       "18               0        0     0    0     0         0          0        0   \n",
       "19               0        0     0    0     0         0          0        0   \n",
       "20               0        0     0    1     0         0          0        0   \n",
       "21               0        0     0    0     0         0          0        0   \n",
       "22               0        0     0    1     0         0          0        0   \n",
       "23               0        0     0    0     0         0          0        0   \n",
       "24               0        0     0    1     1         1          0        0   \n",
       "25               0        0     0    0     0         0          0        1   \n",
       "26               0        0     0    0     0         0          0        0   \n",
       "27               0        0     0    0     0         0          0        0   \n",
       "28               0        1     1    0     0         0          0        0   \n",
       "29               0        1     0    0     0         0          0        0   \n",
       "...            ...      ...   ...  ...   ...       ...        ...      ...   \n",
       "3229             0        0     0    1     0         1          0        0   \n",
       "3230             0        0     0    1     0         1          0        0   \n",
       "3231             0        0     0    0     0         0          0        0   \n",
       "3232             0        0     0    1     1         1          0        0   \n",
       "3233             0        0     0    1     0         0          0        0   \n",
       "3234             0        0     0    1     0         0          0        0   \n",
       "3235             0        1     0    0     0         0          0        0   \n",
       "3236             0        0     1    1     0         0          0        0   \n",
       "3237             0        1     1    0     0         0          0        1   \n",
       "3238             0        0     1    0     0         0          0        0   \n",
       "3239             0        0     0    0     0         0          0        0   \n",
       "3240             0        0     0    1     0         0          0        0   \n",
       "3241             0        0     0    0     0         0          0        1   \n",
       "3242             0        0     0    0     0         0          0        0   \n",
       "3243             0        0     0    1     0         0          0        0   \n",
       "3244             0        1     0    0     0         0          0        1   \n",
       "3245             0        0     0    1     0         0          0        0   \n",
       "3246             0        0     0    1     0         0          0        0   \n",
       "3247             0        0     0    0     0         0          0        0   \n",
       "3248             0        0     0    0     0         0          0        0   \n",
       "3249             0        0     0    0     0         0          0        0   \n",
       "3250             0        0     0    0     0         0          0        0   \n",
       "3251             0        0     0    0     0         0          0        1   \n",
       "3252             0        0     0    0     0         0          0        0   \n",
       "3253             0        0     0    0     0         0          0        1   \n",
       "3254             0        0     0    0     0         0          0        0   \n",
       "3255             0        0     1    0     0         0          0        0   \n",
       "3256             0        1     1    0     0         0          0        0   \n",
       "3257             0        0     0    1     0         0          0        0   \n",
       "3258             0        1     0    0     0         0          0        0   \n",
       "\n",
       "      surprise  trust  \n",
       "0            0      0  \n",
       "1            0      0  \n",
       "2            0      0  \n",
       "3            0      0  \n",
       "4            0      0  \n",
       "5            0      0  \n",
       "6            0      0  \n",
       "7            0      0  \n",
       "8            0      0  \n",
       "9            0      0  \n",
       "10           0      0  \n",
       "11           0      0  \n",
       "12           0      0  \n",
       "13           0      0  \n",
       "14           0      0  \n",
       "15           0      0  \n",
       "16           0      0  \n",
       "17           0      0  \n",
       "18           0      0  \n",
       "19           0      0  \n",
       "20           0      0  \n",
       "21           0      0  \n",
       "22           0      0  \n",
       "23           0      0  \n",
       "24           0      0  \n",
       "25           0      0  \n",
       "26           0      0  \n",
       "27           0      0  \n",
       "28           0      0  \n",
       "29           0      0  \n",
       "...        ...    ...  \n",
       "3229         0      0  \n",
       "3230         0      0  \n",
       "3231         0      0  \n",
       "3232         0      0  \n",
       "3233         0      0  \n",
       "3234         0      0  \n",
       "3235         0      0  \n",
       "3236         0      0  \n",
       "3237         0      0  \n",
       "3238         0      0  \n",
       "3239         0      0  \n",
       "3240         0      0  \n",
       "3241         0      0  \n",
       "3242         0      0  \n",
       "3243         0      0  \n",
       "3244         0      0  \n",
       "3245         0      0  \n",
       "3246         0      0  \n",
       "3247         0      0  \n",
       "3248         0      0  \n",
       "3249         0      0  \n",
       "3250         0      0  \n",
       "3251         0      0  \n",
       "3252         0      0  \n",
       "3253         0      0  \n",
       "3254         0      0  \n",
       "3255         0      0  \n",
       "3256         0      0  \n",
       "3257         0      0  \n",
       "3258         0      0  \n",
       "\n",
       "[3259 rows x 13 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name =[emotion+\"_model.pkl\" for emotion in col_test[2:]]\n",
    "for file in file_name:\n",
    "    loaded_model = joblib.load(file)\n",
    "    output_predict = loaded_model.predict(X_test_tfidf)\n",
    "    cols = str(file).split(\"_\")[0]\n",
    "    data_test[cols]=output_predict\n",
    "data_test"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "AI2_Group5_Emotion_Tweet_Classification.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
